<!DOCTYPE HTML>
<!--
	Stellar by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>6th Workshop on Benchmarking Multi-Target Tracking:Segmenting and Tracking Every Point and Pixel</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header" class="alt">
						<span class="logo"><img src="images/logo.svg" alt="" /></span>
						<h1>Segmenting and Tracking Every Point and Pixel: 6th Workshop on Benchmarking Multi-Target Tracking</h1>
						<p>In conjuction with the International Conference on Computer Vision (ICCV) 2021</p>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul>
							<li><a href="#intro" class="active">Workshop</a></li>
							<li><a href="#speakers-sec">Speakers</a></li>
							<li><a href="#first">Schedule</a></li>
							<li><a href="#second">Competition</a></li>
							<li><a href="#cta">Organizers</a></li>
							<li><a href="http://iccv2021.thecvf.com/home">ICCV 2021</a></li>

						</ul>
					</nav>

				<!-- Main -->
					<div id="main">
						<!-- Introduction -->
							<section id="intro" class="main">
								<div class="spotlight">
									<div class="content">
										<p style="color:Red;font-size:32px;">Please find instructions on how to submit the technical report below.</p>
										<p style="color:Red;font-size:32px;">EXTENSION: All challenges are extended to 8th of October (11:59 PST). Both submissions and technical report deadlines are on 8th of October. Please ignore the codalab phases!</p>
										<header class="major">
											<h2>Workshop</h2>
										</header>
										<h3>Info</h3>
										<p>
										<table style="width:100%">
										  <tr>
										    <td>Time</td>
										    <td>October  17,  2021</td>
										  </tr>
										  <tr>
										    <td>Venue</td>
										    <td><a href="https://iccv2021.thecvf.com/" title="Better luck next year!">ICCV, virtual<a></td>
										  </tr>
										  <tr>
										    <td>Challenge opens</td>
										    <td>July 1st, 2021</td>
										  </tr>
										  <tr>
										    <td>Challenge deadline</td>
										    <td>October 8th, 2021</td>
										  </tr>
										  <tr>
										    <td>Technical report deadline</td>
										    <td>October 8th, 2021</td>
										  </tr>
										  <tr>
										    <td>Recordings</td>
										    <td>Will be avalilbe after the workshop!</td>
										  </tr>
										</table>
										</p>
									</div>

								</div>
							</section>

							<section id="speakers-sec" class="main special">
								<header class="major">
									<h2>Speakers</h2>
								</header>
								<div class="box alt">
									<div class="row gtr-uniform">
										<div class="col-4"><a href='https://hildekuehne.github.io/'><span class="image fit"><img src="images/speakers/hilde_crop.jpg" alt="" /></span><p>Hildegard Kuehne (University Frankfurt/IBM)</p></a></div>
										<div class="col-4"><a href='https://www.cs.cmu.edu/~katef/'><span class="image fit"><img src="images/speakers/katerina_crop.png" alt="" /></span><p>Katerina Fragkiadaki (CMU)</p></a></div>
										<div class="col-4"><a href='http://www.cs.cmu.edu/~deva/'><span class="image fit"><img src="images/speakers/deva_crop.jpg" alt="" /></span><p>Deva Ramanan (CMU)</p></a></div>
										<div class="col-4"><a href='https://davheld.github.io'><span class="image fit"><img src="images/speakers/david_crop.jpg" alt="" /></span><p>David Held (CMU)</p></a></div>
										<div class="col-4"><a href='https://www.philkr.net/'><span class="image fit"><img src="images/speakers/philipp.jpg" alt="" /></span><p>Philipp Krähenbühl (University of Texas)</p></a></div>
										<div class="col-4"><a href='https://alexander-kirillov.github.io/'><span class="image fit"><img src="images/speakers/alexander.jpg" alt="" /></span><p>Alexander Kirillov (FAIR)</p></a></div>
										<div class="col-4"></div>
										<div class="col-4"><a href='https://web.stanford.edu/~rqi/'><span class="image fit"><img src="images/speakers/charles_crop.jpg" alt="" /></span><p>Charles Ruizhongtai Qi (Waymo)</p></a></div>
										<div class="col-4"></div>
									</div>
								</div>
							</section>



					



						<!-- First Section -->
							<section id="first" class="main special">
								<header class="major">
									<h2>Schedule</h2>
								</header>
								<p class="content">
										<div class="table-wrapper">
											<table class="alt">
												<thead>
													<tr>
														<th>Time</th>
														<th>Title</th>
														<th>Speaker</th>
													</tr>
												</thead>
												<tbody>
													<tr>
														<td>10:00-10:20</td>
														<td>Workshop introduction</td>
														<td>Organizers</td>
													</tr>
													<tr>
														<td>10:20-10:50</td>
														<td>Talk 1</td>
														<td>TBD</td>
													</tr>
													<tr>
														<td>10:50-11:20</td>
														<td>Talk 2</td>
														<td>TBD</td>
													</tr>

													<tr>
														<td>11:20-11:50</td>
														<td>Video challenge session</td> 
														<td>TBD</td>
													</tr>
													<tr>
														<td>12:50-12:20</td>
														<td>Video + depth challenge session</td>
														<td>TBD</td>
													</tr>
													<tr>
														<td>12:20-12:50</td>
														<td>LiDAR challenge session</td>
														<td>TBD</td>
													</tr>						
													<tr>
														<td>12:50-2:00</td>
														<td>Break</td>
														<td>-</td>
													</tr>
													<tr>
														<td>2:00-2:30</td>
														<td>Talk 3</td>
														<td>TBD</td>
													</tr>

													<tr>
														<td>2:30-3:00</td>
														<td>Talk 4</td>
														<td>TBD</td>
													</tr>

													<tr>
														<td>3:00-3:30</td>
														<td>Talk 5</td>
														<td>TBD</td>
													</tr>
													<tr>
														<td>3:30-3:50</td>
														<td>Break</td>
														<td>-</td>
													</tr>
													<tr>
														<td>3:50-4:20</td>
														<td>Talk 5</td>
														<td>TBD</td>
													</tr>

													<tr>
														<td>4:20-4:50</td>
														<td>Talk 6</td>
														<td>TBD</td>
													</tr>

													<tr>
														<td>4:50-4:10</td>
														<td>Talk 7</td>
														<td>TBD</td>
													</tr>
													<tr>
														<td>5:10-5:30</td>
														<td>Break</td>
														<td>-</td>
													</tr>
													<tr>
														<td>5:30-6:30</td>
														<td>Round table discussion</td>
														<td>All speakers</td>
													</tr>
													<tr>
														<td>6:30-6:40</td>
														<td>Closing remarks</td>
														<td>Organizers</td>
													</tr>
												</tbody>
											</table>
										</div>
									</section>


								</p>
							</section>

						<!-- Second Section -->
							<section id="second" class="main special">
								<header class="major">
									<h2>Competitions</h2>
									<p>For the 6th edition of our <i>Benchmarking Multi-Target Tracking</i> workshop, we are planning to take multi-object tracking and segmentation to the next level. In this edition, we will organize three challenging competitions, for which we require to assign semantic classes and track identities to all pixels in a video or 3D points based either on a monocular video or a LiDAR stream.</p>
								</header>
								<p class="content">
				

									<h3>Video track</h3> 
									<span class="image fit"><img width="100" src="images/teaser_step.png" alt="" /></span>
									For this track we extended two existing datasets (<a href="http://www.cvlibs.net/publications/Geiger2012CVPR.pdf">KITTI</a> and <a href="https://arxiv.org/abs/2010.07548">MOTChallenge</a>) with dense, pixel-precise labels in both spatial and temporal domain: KITTI-STEP and MOTChallenge-STEP. For MOTChallenge-STEP, we have extended the instance-level annotations of two training and two test sequences of <a href="https://arxiv.org/abs/1902.03604">MOTChallenge-MOTS</a> labels and 21 training and 29 test sequences of <a href="https://arxiv.org/abs/1902.03604">KITTI-MOTS</a> labels. For more information we refer to <a href="https://arxiv.org/abs/2102.11859">our recent paper</a>. The task will be to assign a semantic and unique instance label to every pixel of the video. 
									<br/></br>
									<strong>Dataset: </strong> Image sequences are avalible at the <a href="http://www.cvlibs.net/datasets/kitti/eval_tracking.php">KITTI tracking dataset website</a>. KITTI-STEP labels and instructions are avalilble <a href="https://github.com/google-research/deeplab2/blob/main/g3doc/setup/kitti_step.md">here</a>. The MOTChallenge-STEP data and according instructions can be found <a href="https://github.com/google-research/deeplab2/blob/main/g3doc/setup/motchallenge_step.md">here</a>. More information can be found at the corresponding test servers.<br/>
									<strong>Baselines: </strong> Our baselines and pre-trained models are avalible <a href="https://github.com/google-research/deeplab2">here</a>. <br/>
									<strong>Metric: </strong> <a href="https://github.com/google-research/deeplab2/blob/main/evaluation/segmentation_and_tracking_quality.py">Segmentation and Tracking Quality (STQ).</a> <br/>
									<strong>Test server: </strong> The KITTI-STEP test server can be found <b><a href="http://cvlibs.net/datasets/kitti/eval_step.php">here</a></b>. The MOTChallenge-STEP test server is open <b><a href="https://motchallenge.net/data/STEP-ICCV21/">here</a></b>. We highly encourage submissions to both datasets, but also allow entries to only one of the datasets.
									<br/></br>
									<hr />
									<h3>LiDAR track</h3>
 									<span class="image fit"><img width="100" src="images/lidar.png" alt="" /></span>
									This challenge will be based on the <a href="https://arxiv.org/abs/1904.01416">SemanticKITTI</a> dataset, introduced in the context of <a href="https://arxiv.org/abs/1904.01416">LiDAR semantic segmentation</a> and <a href="https://arxiv.org/abs/2003.02371">panoptic segmentation</a>. 
									The dataset is densely labeled in the spatial and temporal domain, which makes it a perfect test-bed for our 4D panoptic LiDAR segmentation challenge, as introduced in our recent paper on <a href="https://arxiv.org/abs/2102.12472">4D Panoptic LiDAR segmentation</a>. The task will be to assign a semantic and unique instance label to every 3D LiDAR point. 
									<br/></br>
									<strong>Dataset: </strong> LiDAR sequences, labels and dataset instructions are avalible at the <a href="http://semantic-kitti.org/dataset.html#download">Semantic KITTI website</a>. <br/>
									<strong>Baselines: </strong> Our baselines and pre-trained models are avalible <a href="https://github.com/MehmetAygun/4D-PLS">here</a>. <br/>
									<strong>Metric: </strong> <a href="https://github.com/MehmetAygun/4D-PLS/blob/master/utils/evaluate_4dpanoptic.py">LiDAR Segmentation and Tracking Quality (LSTQ)</a> <br/>
									<strong>Test server: </strong> <b>The challenge submission platform is open, <a href="https://competitions.codalab.org/competitions/26369">link</a>!</b>
									<br/></br>								
									<hr />
									<h3>Video + depth track</h3> 
 									<span class="image fit"><img width="100" src="images/dvps.gif" alt="" /></span>
									This track will be based on the recently introduced <a href="https://arxiv.org/pdf/2012.05258.pdf">SemanticKITTI-DVPS</a> dataset, that augments LiDAR-based <a href="https://arxiv.org/abs/1904.01416">SemanticKITTI</a> dataset with pixel-precise semantic and instance labels of images, derived from LiDAR labels in a semi-automated manner, providing semantic and depth labels needed for evaluation of joint video panoptic segmentation and monocular depth estimation. In addition to assigning semantic and instance labels, this track requires a depth estimate for every pixel.
									<br/></br>
									<strong>Dataset: </strong>The dataset can be found <a href="https://github.com/joe-siyuan-qiao/ViP-DeepLab/tree/master/semkitti-dvps">here</a> <br/>
									<strong>Baselines: </strong> Our baseline can be found <a href="https://github.com/google-research/deeplab2/blob/main/configs/semkitti_dvps/vip_deeplab/resnet50_beta_os32.textproto">here</a><br/>
									<strong>Metric: </strong> <a href="https://github.com/joe-siyuan-qiao/ViP-DeepLab/blob/master/semkitti-dvps/eval_dstq.py">Depth-aware Segmentation and Tracking Quality (DSTQ)</a> <br/>
									<strong>Test server: </strong><b>The challenge submission platform is open, <a href="https://competitions.codalab.org/competitions/33634">link</a>!</b>
									<hr />
									For each challenge, we will award the <b>challenge winner</b> and the <b>most innovative</b> entry that our committee will select based on the submitted 4-page abstracts and invite both to give a short talk at our workshop. 
									We will rank all methods with respect to the recently introduced <a href="https://arxiv.org/abs/2102.11859">Segmentating and Tracking Quality (STQ) metric</a> and its task-specific variants.
									<br/></br>
									<strong>STQ (TF2): </strong> The tensorflow 2 reference implementation of STQ is avalible <a href="https://github.com/google-research/deeplab2/blob/main/evaluation/segmentation_and_tracking_quality.py">here.</a> <br/>
									<strong>STQ (Numpy): </strong> The numpy reference implementation of STQ is avalible <a href="https://github.com/google-research/deeplab2/blob/main/evaluation/numpy">here.</a> <br/>
									<hr />
									<h3>Technical report format</h3>
									Please follow a <strong>two-column layout</strong> for your submission. The technical report should <strong>at most contain 4 pages</strong> including references. However, shorter reports of 2 pages are very welcome. Submissions are <strong>not blind</strong>, hence, please include all authors on the submission. Only participants with a submitted report are considered for the reward and to present on the workshop. Please <strong>make your challenge entry public</strong> once submitted and make it clear to which method the report belongs. All reports should be send to Aljosa Osep (aljosa.osep [at] tum . de) and Mark Weber (mark-cs.weber [at] tum . de). <strong>The deadline is October 8th, 11:59 PST.</strong>
								</p>
							</section>

						<!-- Get Started -->
							<section id="cta" class="main special">
								<header class="major">
									<h2>Organizers</h2>
									<div class="box alt">
										<div class="row gtr-uniform">
											<div class="col-2"></div>
											<div class="col-4"><span class="image fit"><img src="images/organizers/osep_cropped.jpg" alt="" /></span><p>Aljoša Ošep (TUM)</p></div>
											<div class="col-4"><span class="image fit"><img src="images/organizers/weber.jpg" alt="" /></span><p>Mark Weber (TUM)</p></div>
											<div class="col-2"></div>
											<div class="col-4"><span class="image fit"><img src="images/organizers/dendorfer.jpg" alt="" /></span><p>Patrick Dendorfer (TUM)</p></div>
											<div class="col-4"><span class="image fit"><img src="images/organizers/behley.jpg" alt="" /></span><p>Jens Behley (Uni Bonn)</p></div>
											<div class="col-4"><span class="image fit"><img src="images/organizers/cyrill-web-1024.jpg" alt="" /></span><p>Cyrill Stachniss (Uni Bonn)</p></div>
											<div class="col-4"><span class="image fit"><img src="images/organizers/geiger.jpg" alt="" /></span><p>Andreas Geiger (MPI/Tübingen)</p></div>
											<div class="col-4"><span class="image fit"><img src="images/organizers/jun.jpg" alt="" /></span><p>Jun Xie (Google)</p></div>
											<div class="col-4"><span class="image fit"><img src="images/organizers/qiao.jpg" alt="" /></span><p>Siyuan Qiao (JHU)</p></div>
											<div class="col-4"><span class="image fit"><img src="images/organizers/cremers_large.jpg" alt="" /></span><p>Daniel Cremers (TUM)</p></div>
											<div class="col-4"><span class="image fit"><img src="images/organizers/chen.jpg" alt="" /></span><p>Liang-Chieh Chen (Google)</p></div>
											<div class="col-4"><span class="image fit"><img src="images/organizers/lealtaixe_cropped.jpg" alt="" /></span><p>Laura Leal-Taixé (TUM)</p></div>
										</div>
									</div>
									<div class="box alt">
										<div class="col-2"></div>
										<div class="row gtr-uniform">
											<div class="col-2"></div>
											<div class="col-4"><span class="image fit"><img src="images/affiliations/tum.png" alt="" /></span></div>
											<div class="col-4"><span class="image fit"><img src="images/affiliations/bonn.jpg" alt="" /></span></div>
											<div class="col-2"></div>
											<div class="col-4"><span class="image fit"><img src="images/affiliations/google.jpg" alt="" /></span></div>
											<div class="col-4"><span class="image fit"><img src="images/affiliations/mpi.jpeg" alt="" /></span></div>
											<div class="col-4"><span class="image fit"><img src="images/affiliations/jhu.jpg" alt="" /></div>
										</div>
									</div>
								</header>
								

							</section>

						<!-- Get Started -->
							<section id="sponsor" class="main special">
								<header class="major">
									<h2>Sponsor</h2>
									<p>We thank the sponsor of this workshop.</p>
									<div class="box alt">
										<div class="row aln-center">
											<div class="col-5"><span class="image fit"><img src="images/affiliations/google.jpg" alt="" /></span></div>
										</div>
									</div>
								</header>
								

							</section>

					</div>

				<!-- Footer -->
					<footer id="footer">
						<p class="copyright">Template from: <a href="https://html5up.net">HTML5 UP</a>.</p>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>